import os
import sys
import logging
import re  # âœ… æ–°å¢ï¼šç”¨äºæ­£åˆ™æå–ç« èŠ‚å·
from sqlalchemy import create_engine, text
from urllib.parse import quote_plus
from docx import Document
from docxcompose.composer import Composer 
from utils.zzp.create_catalogue import safe_path_component # å¼•å…¥å½’ä¸€åŒ–å‡½æ•° 

# ==========================================
# 0. åŸºç¡€é…ç½®ä¸å¯¼å…¥
# ==========================================
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if project_root not in sys.path:
    sys.path.append(project_root)
import server_config
from utils.zzp import sql_config as config

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

TARGET_ROOT_DIR = server_config.MERGE_DIR

def get_db_connection():
    encoded_password = quote_plus(config.password)
    db_url = f"mysql+pymysql://{config.username}:{encoded_password}@{config.host}:{config.port}/{config.database}"
    return create_engine(db_url)

def get_chapter_sort_key(file_path):
    """
    âœ… æ–°å¢å‡½æ•°ï¼šä»æ–‡ä»¶è·¯å¾„ä¸­æå–ç« èŠ‚å·è¿›è¡Œè‡ªç„¶æ’åº
    ä¾‹å¦‚ï¼š"/path/to/2.1.1 ç°çŠ¶åˆ†æ.docx" -> [2, 1, 1]
    è¿™æ ·å¯ä»¥ç¡®ä¿ 1.2 åœ¨ 1.10 å‰é¢ï¼Œä¸” 3.1 åœ¨ 1.1 åé¢
    """
    filename = os.path.basename(file_path)
    # æ­£åˆ™åŒ¹é…å¼€å¤´çš„æ•°å­—å’Œç‚¹ï¼Œä¾‹å¦‚ "3.2.2.1"
    match = re.match(r'^([\d\.]+)', filename)
    if match:
        # å°† "3.2.1" å˜æˆ [3, 2, 1]
        try:
            return [int(n) for n in match.group(1).split('.') if n]
        except ValueError:
            return [float('inf')] # è§£æå¤±è´¥æ”¾åˆ°æœ€å
    return [float('inf')] # æ²¡æœ‰æ•°å­—å¼€å¤´çš„æ–‡ä»¶æ”¾åˆ°æœ€å

def merge_docx_files(source_files, target_path):
    """
    åˆå¹¶å¤šä¸ª docx æ–‡ä»¶çš„æ ¸å¿ƒé€»è¾‘
    """
    try:
        if not source_files:
            return False, "æ²¡æœ‰å¯åˆå¹¶çš„æ–‡ä»¶"

        # 1. ä»¥ç¬¬ä¸€ä¸ªæ–‡ä»¶ä¸ºæ¯ç‰ˆ
        master_doc = Document(source_files[0])
        composer = Composer(master_doc)

        # 2. ä¾æ¬¡è¿½åŠ åç»­æ–‡ä»¶
        for i in range(1, len(source_files)):
            doc_path = source_files[i]
            if os.path.exists(doc_path):
                try:
                    sub_doc = Document(doc_path)
                    composer.append(sub_doc)
                except Exception as sub_e:
                    logger.warning(f"âš ï¸ è¿½åŠ æ–‡ä»¶å¤±è´¥ {doc_path}: {sub_e}")
            else:
                logger.warning(f"âš ï¸ åˆå¹¶æ—¶è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {doc_path}")

        # 3. ä¿å­˜
        composer.save(target_path)
        return True, "åˆå¹¶æˆåŠŸ"
    except Exception as e:
        logger.error(f"åˆå¹¶æ–‡ä»¶å‡ºé”™: {e}")
        return False, str(e)

def get_sorted_source_files(target_type_name: str, target_report_name: str, user_id=None):
    engine = get_db_connection()
    with engine.connect() as conn:
        sql_type = text("SELECT id FROM report_type WHERE type_name = :t_name LIMIT 1")
        result_type = conn.execute(sql_type, {"t_name": target_type_name}).fetchone()
        if not result_type:
            return []
        type_id = result_type[0]
        
        # [MODIFIED] Filter by user_id, and fetch storage_dir
        query_report = "SELECT id, storage_dir FROM report_name WHERE type_id = :tid AND report_name = :r_name"
        params = {"tid": type_id, "r_name": target_report_name}
        if user_id is not None:
            query_report += " AND user_id = :uid"
            params["uid"] = user_id
        query_report += " LIMIT 1"
        
        sql_report = text(query_report)
        result_report = conn.execute(sql_report, params).fetchone()
        
        if not result_report:
            return []
        report_name_id = result_report[0]
        storage_dir = result_report[1]

        # ç¡®å®šæŠ¥å‘Šçš„ç‰©ç†æ–‡ä»¶å¤¹åç§°
        base_dir = server_config.get_user_report_dir(user_id)
        
        # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“è®°å½•çš„ storage_dir
        if storage_dir:
             report_dir_name = storage_dir
        else:
             # å…¼å®¹æ—§æ•°æ®ï¼šå°è¯•å½’ä¸€åŒ–è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨åŸå§‹åç§°
             safe_name = safe_path_component(target_report_name)
             if os.path.exists(os.path.join(base_dir, target_type_name, safe_name)):
                 report_dir_name = safe_name
             else:
                 report_dir_name = target_report_name
        
        full_report_dir = os.path.join(base_dir, target_type_name, report_dir_name)

        sql_files = text("""
            SELECT file_name FROM report_catalogue 
            WHERE report_name_id = :rid 
            ORDER BY sortOrder ASC
        """)
        file_results = conn.execute(sql_files, {"rid": report_name_id}).fetchall()
        raw_source_files = []
        for row in file_results:
            file_name = row[0]
            if file_name:
                # æ‹¼æ¥å®Œæ•´è·¯å¾„
                full_path = os.path.join(full_report_dir, file_name)
                if os.path.exists(full_path):
                    raw_source_files.append(full_path)
                else:
                    logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")

    # ä½¿ç”¨è‡ªç„¶æ’åºå¯¹æ–‡ä»¶è¿›è¡Œé‡æ–°æ’åº
    # å› ä¸ºæ•°æ®åº“é‡Œçš„ sortOrder å¯èƒ½æ˜¯æŒ‰æ’å…¥é¡ºåºï¼Œä¸ä¸€å®šå®Œå…¨å¯¹åº”ç« èŠ‚å·é€»è¾‘
    # å¦‚æœæ‚¨ä¿¡ä»» sortOrderï¼Œå¯ä»¥è·³è¿‡è¿™ä¸€æ­¥ã€‚è¿™é‡Œä¸ºäº†ä¿é™©ï¼Œå†æ¬¡æŒ‰ç« èŠ‚å·æ’åºã€‚
    sorted_files = sorted(raw_source_files, key=get_chapter_sort_key)
    # ä¿®æ­£ï¼šæ—¢ç„¶æ•°æ®åº“å·²ç»æœ‰ sortOrderï¼Œæˆ‘ä»¬åº”è¯¥ä¼˜å…ˆä¿¡èµ–æ•°æ®åº“çš„é¡ºåºã€‚
    # é™¤é sortOrder ä¸å¯é ã€‚æ ¹æ®ä¹‹å‰é€»è¾‘ï¼Œä¼¼ä¹æ²¡ç”¨ sortOrder è€Œæ˜¯æŸ¥å‡ºæ¥åå†æ’ï¼Ÿ
    # åŸä»£ç åªå†™äº† ORDER BY sortOrder ASCï¼Œç„¶åå°±æ²¡åŠ¨ä½œäº†ã€‚
    # å‡è®¾æ•°æ®åº“é¡ºåºæ˜¯å¯¹çš„ã€‚
    return sorted_files

def process_report_merge(type_name: str, report_name: str, user_id=None):
    """
    æ‰§è¡Œåˆå¹¶æµç¨‹çš„ä¸»å…¥å£
    :param type_name: æŠ¥å‘Šç±»å‹
    :param report_name: æŠ¥å‘Šåç§°
    :param user_id: ç”¨æˆ·ID
    :return: (bool, message)
    """
    # 1. è·å–æºæ–‡ä»¶åˆ—è¡¨
    source_files = get_sorted_source_files(type_name, report_name, user_id)
    if not source_files:
        return False, f"æœªæ‰¾åˆ°è¯¥æŠ¥å‘Šä¸‹çš„å­æ–‡ä»¶: {report_name}"

    # 2. å‡†å¤‡ç›®æ ‡ç›®å½•
    # [MODIFIED] Use user-specific merge dir
    base_merge_dir = server_config.get_user_merge_dir(user_id)
    
    save_dir = os.path.join(base_merge_dir, type_name)
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    # 3. æ„é€ ç›®æ ‡æ–‡ä»¶è·¯å¾„
    target_file_name = f"{report_name}.docx"
    target_path = os.path.join(save_dir, target_file_name)

    logger.info(f"å¼€å§‹åˆå¹¶ {len(source_files)} ä¸ªæ–‡ä»¶ -> {target_path}")

    # 4. æ‰§è¡Œåˆå¹¶
    success, msg = merge_docx_files(source_files, target_path)
    
    # 5. [NEW] å¦‚æœåˆå¹¶æˆåŠŸï¼Œå°†è®°å½•å†™å…¥æ•°æ®åº“
    if success:
        try:
            save_merged_record_to_db(type_name, report_name, target_path, user_id)
            logger.info(f"âœ… åˆå¹¶è®°å½•å·²å†™å…¥æ•°æ®åº“: {report_name}")
        except Exception as db_e:
            logger.error(f"âŒ å†™å…¥æ•°æ®åº“å¤±è´¥: {db_e}")
            # æ³¨æ„ï¼šè¿™é‡Œè™½ç„¶æ•°æ®åº“å†™å…¥å¤±è´¥ï¼Œä½†æ–‡ä»¶åˆå¹¶æ˜¯æˆåŠŸçš„ã€‚
            # æˆ‘ä»¬å¯ä»¥é€‰æ‹©è¿”å›æˆåŠŸä½†å¸¦è­¦å‘Šï¼Œæˆ–è€…è§†ä¸ºå¤±è´¥ã€‚
            # é€šå¸¸ä¸ºäº†æ•°æ®ä¸€è‡´æ€§ï¼Œåº”è¯¥è§†ä¸ºæŸç§ç¨‹åº¦çš„å¤±è´¥ï¼Œä½†æ–‡ä»¶å·²ç»ç”Ÿæˆäº†ã€‚
            # è¿™é‡Œæˆ‘ä»¬ä»…è®°å½•æ—¥å¿—ï¼Œä¾ç„¶è¿”å›æˆåŠŸã€‚

    return success, msg

def save_merged_record_to_db(type_name, report_name, file_path, user_id):
    """
    å°†åˆå¹¶åçš„æŠ¥å‘Šè®°å½•å†™å…¥ report_merged_record è¡¨
    """
    engine = get_db_connection()
    with engine.begin() as conn: # ä½¿ç”¨äº‹åŠ¡
        # 1. è·å– type_id
        sql_type = text("SELECT id FROM report_type WHERE type_name = :t_name LIMIT 1")
        res_type = conn.execute(sql_type, {"t_name": type_name}).fetchone()
        if not res_type:
            raise Exception(f"æœªæ‰¾åˆ°æŠ¥å‘Šç±»å‹: {type_name}")
        type_id = res_type[0]

        # 2. è·å– report_name_id
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ® user_id è¿‡æ»¤ï¼Œç¡®ä¿å…³è”åˆ°æ­£ç¡®çš„æŠ¥å‘Š
        sql_report = "SELECT id FROM report_name WHERE type_id = :tid AND report_name = :r_name"
        params = {"tid": type_id, "r_name": report_name}
        if user_id is not None:
            sql_report += " AND user_id = :uid"
            params["uid"] = user_id
        sql_report += " LIMIT 1"
        
        res_report = conn.execute(text(sql_report), params).fetchone()
        if not res_report:
            raise Exception(f"æœªæ‰¾åˆ°æŠ¥å‘Šåç§°è®°å½•: {report_name}")
        report_name_id = res_report[0]

        # 3. æ’å…¥æˆ–æ›´æ–° report_merged_record
        # ç­–ç•¥ï¼šå¦‚æœå·²å­˜åœ¨åŒååˆå¹¶è®°å½•ï¼Œæ˜¯è¦†ç›–è¿˜æ˜¯æ–°å¢ï¼Ÿ
        # é€šå¸¸åˆå¹¶æ“ä½œä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼Œæ‰€ä»¥æ•°æ®åº“è®°å½•ä¹Ÿåº”è¯¥æ›´æ–°æˆ–è¦†ç›–ã€‚
        # è¿™é‡Œæˆ‘ä»¬å…ˆæŸ¥è¯¢æ˜¯å¦å­˜åœ¨
        check_sql = "SELECT id FROM report_merged_record WHERE report_name_id = :rid AND type_id = :tid"
        check_params = {"rid": report_name_id, "tid": type_id}
        if user_id is not None:
            check_sql += " AND user_id = :uid"
            check_params["uid"] = user_id
            
        existing = conn.execute(text(check_sql), check_params).fetchone()
        
        if existing:
            # æ›´æ–°
            update_sql = """
                UPDATE report_merged_record 
                SET file_path = :path, create_time = NOW(), merged_report_name = :m_name
                WHERE id = :eid
            """
            conn.execute(text(update_sql), {
                "path": file_path, 
                "m_name": report_name, 
                "eid": existing[0]
            })
        else:
            # æ’å…¥
            insert_sql = """
                INSERT INTO report_merged_record 
                (type_id, report_name_id, merged_report_name, file_path, create_time, user_id)
                VALUES (:tid, :rid, :m_name, :path, NOW(), :uid)
            """
            # å¦‚æœ user_id ä¸º Noneï¼Œæˆ‘ä»¬éœ€è¦ç»™ä¸€ä¸ªé»˜è®¤å€¼å—ï¼Ÿæ•°æ®åº“å®šä¹‰æ˜¯ NOT NULL DEFAULT 2
            # ä½†æˆ‘ä»¬åœ¨ä»£ç é‡Œåº”è¯¥å°½é‡æ˜ç¡®ã€‚å¦‚æœ user_id æ˜¯ Noneï¼Œå¯èƒ½éœ€è¦å¤„ç†ã€‚
            # ä¸è¿‡æ ¹æ®è°ƒç”¨é“¾ï¼Œuser_id åº”è¯¥ä¼ è¿›æ¥äº†ã€‚
            real_uid = user_id if user_id is not None else 2 # Fallback to default user 2
            
            conn.execute(text(insert_sql), {
                "tid": type_id,
                "rid": report_name_id,
                "m_name": report_name,
                "path": file_path,
                "uid": real_uid
            })

if __name__ == "__main__":
    INPUT_TYPE = "èµ„äº§æŠ¥å‘Š"
    INPUT_NAME = "123456"
    print(f"ğŸš€ å¼€å§‹åˆå¹¶ä»»åŠ¡: [{INPUT_TYPE}] - [{INPUT_NAME}]")
    success, msg = process_report_merge(INPUT_TYPE, INPUT_NAME)
    if success:
        print(f"âœ… {msg}")
    else:
        print(f"âŒ {msg}")
