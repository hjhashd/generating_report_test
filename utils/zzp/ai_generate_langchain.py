import os
import sys
import json
import re
import logging
import time
from datetime import datetime
from typing import List

# æ•°æ®åº“ä¸åŠ å¯†ç›¸å…³
import pymysql
import pdfplumber
from sqlalchemy import create_engine, text
from urllib.parse import quote_plus
from docx import Document
from cryptography.fernet import Fernet

# LangChain ç›¸å…³åº“
from langchain_ollama import ChatOllama
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, messages_to_dict, messages_from_dict
from utils.redis_client import get_redis_client
from utils.chat_session_manager import ChatSessionManager

# ==========================================
# 0. åŸºç¡€é…ç½® & å¯†é’¥ç®¡ç†
# ==========================================
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

# æ·»åŠ  generate_report_test åˆ° sys.path ä»¥å¯¼å…¥ server_config
generate_report_root = os.path.dirname(project_root)
if generate_report_root not in sys.path:
    sys.path.append(generate_report_root)
import server_config

from zzp import sql_config as config

BASE_DIR = server_config.INFERRENCE_DIR
ENCRYPTION_KEY = b'8P_Gk9wz9qKj-4t8z9qKj-4t8z9qKj-4t8z9qKj-4t8=' 
cipher_suite = Fernet(ENCRYPTION_KEY)
logger = logging.getLogger(__name__)

# ==========================================
# 1. å…¨å±€ä¼šè¯ç®¡ç† (Redis + Memory)
# ==========================================
# Initialize Manager (using default 'chat_session' type to match verified state)
session_manager = ChatSessionManager(session_type="chat_session")

# ==========================================
# 2. æ•°æ®åº“ä¸å·¥å…·å‡½æ•°
# ==========================================
def get_db_connection():
    encoded_password = quote_plus(config.password)
    db_url = f"mysql+pymysql://{config.username}:{encoded_password}@{config.host}:{config.port}/{config.database}"
    return create_engine(db_url)

def decrypt_text(encrypted_str):
    if not encrypted_str: return None
    try:
        return cipher_suite.decrypt(encrypted_str.encode()).decode()
    except Exception:
        # Fallback: if it looks like a raw key (starts with "sk-"), return it directly
        if encrypted_str.startswith("sk-"):
            return encrypted_str
        return ""

def get_llm_config_by_id(model_id, user_id=None):
    engine = get_db_connection()
    # å¢åŠ  user_id æ ¡éªŒï¼šåªèƒ½æŸ¥åˆ° å…¬ç”¨æ¨¡å‹(user_id IS NULL) æˆ– è‡ªå·±çš„æ¨¡å‹
    sql_str = "SELECT llm_type, model_name, api_key, base_url FROM llm_config WHERE id = :id"
    if user_id is not None:
        sql_str += " AND (user_id IS NULL OR user_id = :user_id)"
    
    sql = text(sql_str)
    try:
        with engine.connect() as conn:
            params = {"id": model_id}
            if user_id is not None:
                params["user_id"] = user_id
                
            result = conn.execute(sql, params).fetchone()
            if result:
                llm_type, model_name, encrypted_key, base_url = result
                api_key = decrypt_text(encrypted_key) if encrypted_key else ""
                return {
                    "llm_type": llm_type, "model_name": model_name,
                    "api_key": api_key, "base_url": base_url
                }
    except Exception as e:
        logger.error(f"è¯»å–é…ç½®å¤±è´¥: {e}")
    return None

def get_default_llm_config():
    """è·å–é»˜è®¤çš„ LLM é…ç½® (ç”¨äºæœªæŒ‡å®š ID æ—¶)"""
    engine = get_db_connection()
    # ä¼˜å…ˆè·å–æœ€æ–°çš„é…ç½® (å‡è®¾ ID è¶Šå¤§è¶Šæ–°)
    sql = text("SELECT llm_type, model_name, api_key, base_url FROM llm_config ORDER BY id DESC LIMIT 1")
    try:
        with engine.connect() as conn:
            result = conn.execute(sql).fetchone()
            if result:
                llm_type, model_name, encrypted_key, base_url = result
                api_key = decrypt_text(encrypted_key) if encrypted_key else ""
                return {
                    "llm_type": llm_type, "model_name": model_name,
                    "api_key": api_key, "base_url": base_url
                }
    except Exception as e:
        logger.error(f"è¯»å–é»˜è®¤é…ç½®å¤±è´¥: {e}")
    return None

def get_files_by_material_names(material_name_list, user_id=None):
    if not material_name_list: return {}
    engine = get_db_connection()
    try:
        with engine.connect() as conn:
            # å¢åŠ  user_id æ ¡éªŒï¼šåªèƒ½æŸ¥åˆ°è‡ªå·±çš„æ–‡ä»¶ (å‡è®¾ file_item å…³è”çš„ file_structure æœ‰ user_idï¼Œæˆ–è€… file_item æœ¬èº«æœ‰ user_id)
            # æ ¹æ®ä¹‹å‰çš„ queryAll.pyï¼Œfile_item é€šè¿‡ folder_id å…³è” file_structureï¼Œfile_structure æœ‰ user_id
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå…ˆåªæŸ¥ file_itemï¼Œå‡è®¾åç»­ä¼šå®Œå–„æ–‡ä»¶éš”ç¦»ã€‚
            # ä¸ºäº†ä¸¥è°¨ï¼Œæˆ‘ä»¬åº”è¯¥ JOIN file_structure å¹¶æ ¡éªŒ user_id
            sql_str = """
                SELECT f.file_name, f.file_path 
                FROM file_item f
                JOIN file_structure s ON f.folder_id = s.id
                WHERE f.file_name IN :names
            """
            if user_id is not None:
                sql_str += " AND s.user_id = :user_id"
            
            sql = text(sql_str)
            params = {"names": tuple(material_name_list)}
            if user_id is not None:
                params["user_id"] = user_id

            result = conn.execute(sql, params).fetchall()
            return {row[0]: row[1] for row in result}
    except Exception as e:
        logger.error(f"æ–‡ä»¶æŸ¥è¯¢å¤±è´¥: {e}")
        return {}

def read_file_content(file_path):
    full_path = os.path.join(BASE_DIR, file_path.lstrip('/'))
    if not os.path.exists(full_path): return ""
    try:
        if full_path.endswith('.docx'):
            doc = Document(full_path)
            return "\n".join([para.text for para in doc.paragraphs]).strip()
        elif full_path.endswith('.pdf'):
            with pdfplumber.open(full_path) as pdf:
                return "\n".join([page.extract_text() or "" for page in pdf.pages]).strip()
        else:
            with open(full_path, 'r', encoding='utf-8') as f:
                return f.read().strip()
    except Exception:
        return ""

# def init_llm_instance(config_data):
#     if not config_data: raise ValueError("é…ç½®æ•°æ®ä¸ºç©º")
#     llm_type = config_data['llm_type']
#     model_name = config_data['model_name']
#     base_url = config_data['base_url']
#     api_key = config_data['api_key']

#     if llm_type == "local":
#         return ChatOllama(model=model_name, base_url=base_url, temperature=0.2, num_ctx=8192)
#     elif llm_type in ["online", "custom"]:
#         return ChatOpenAI(api_key=api_key, base_url=base_url, model=model_name, temperature=0.2, streaming=True)
#     else:
#         raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {llm_type}")

def init_llm_instance(config_data):
    if not config_data: raise ValueError("é…ç½®æ•°æ®ä¸ºç©º")

    llm_type = config_data['llm_type']
    model_name = config_data['model_name']
    base_url = config_data['base_url']
    api_key = config_data['api_key']

    # ================= è°ƒè¯•ä»£ç å¼€å§‹ =================
    print(f"\nğŸ” [è°ƒè¯•ä¿¡æ¯] æ¨¡å‹ç±»å‹: {llm_type}")
    print(f"ğŸ” [è°ƒè¯•ä¿¡æ¯] æ¨¡å‹åç§°: {model_name}")
    print(f"ğŸ” [è°ƒè¯•ä¿¡æ¯] Base URL: '{base_url}'") # æ³¨æ„çœ‹æœ‰æ²¡æœ‰ç©ºæ ¼ï¼Œæˆ–è€…æ˜¯å¦ç¼ºäº† /v1
    
    if api_key:
        # åªæ‰“å°å‰5ä½å’Œå5ä½ï¼Œé˜²æ­¢æ³„éœ²ï¼Œç¡®è®¤è§£å¯†æ˜¯å¦æˆåŠŸ
        masked_key = f"{api_key[:5]}...{api_key[-5:]}" if len(api_key) > 10 else "***"
        print(f"ğŸ” [è°ƒè¯•ä¿¡æ¯] API Key (è§£å¯†å): {masked_key}")
        print(f"ğŸ” [è°ƒè¯•ä¿¡æ¯] API Key é•¿åº¦: {len(api_key)}")
    else:
        print(f"ğŸ” [è°ƒè¯•ä¿¡æ¯] API Key ä¸ºç©º!")
    # ================= è°ƒè¯•ä»£ç ç»“æŸ =================

    print(f"ğŸš€ åˆå§‹åŒ–æ¨¡å‹: [{llm_type}] {model_name}")
    
    if llm_type == "local":
        return ChatOllama(model=model_name, base_url=base_url, temperature=0.2, num_ctx=8192, timeout=60)
    elif llm_type in ["online", "custom"]:
        return ChatOpenAI(
            api_key=api_key, 
            base_url=base_url, 
            model=model_name, 
            temperature=0.2, 
            streaming=True,
            timeout=60
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {llm_type}")

# ==========================================
# 3. æ ¸å¿ƒå¯¼å‡ºå‡½æ•° (Chat_generator_stream)
# ==========================================
def Chat_generator_stream(folder_name, material_name_list, instruction, model_id, task_id, user_id=None):
    """
    æµå¼ç”Ÿæˆå™¨æ ¸å¿ƒé€»è¾‘
    å‚æ•° task_id: ç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„å†å²è®°å½•
    å‚æ•° user_id: ç”¨äºæ•°æ®æƒé™éš”ç¦»
    """
    # global CHAT_SESSIONS (Removed)

    # 1. éªŒè¯é…ç½®
    llm_config = get_llm_config_by_id(model_id, user_id=user_id)
    if not llm_config:
        yield f"data: {json.dumps({'error': 'Model config not found'})}\n\n"
        return

    # 2. åˆå§‹åŒ–æˆ–è·å–å†å²è®°å½•
    current_history = session_manager.get_session(task_id)
    if not current_history:
        current_history = []

    # 3. å‡†å¤‡ææ–™ä¸Šä¸‹æ–‡
    full_materials_text = ""
    has_materials = False
    if material_name_list and len(material_name_list) > 0:
        file_map = get_files_by_material_names(material_name_list, user_id=user_id)
        if file_map:
            content_parts = []
            for name, path in file_map.items():
                text_content = read_file_content(path)
                if text_content:
                    content_parts.append(f"ã€å‚è€ƒææ–™ï¼š{name}ã€‘\n{text_content}\n")
            full_materials_text = "\n".join(content_parts)
            if full_materials_text:
                has_materials = True

    # 4. æ„å»º System Prompt
    current_date = datetime.now().strftime('%Y-%m-%d')
    if has_materials:
        system_content = f"""
ä»Šå¤©æ—¥æœŸï¼š{current_date}
ä½ æ˜¯ä¸€ä¸ªæ”¿åŠ¡ææ–™æ’°å†™è¾…åŠ©AIã€‚

ã€å‚è€ƒææ–™ã€‘
{full_materials_text}

ã€ä»»åŠ¡æŒ‡ä»¤ã€‘
è¯·åŸºäºä¸Šè¿°ææ–™ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. ä¸¥æ ¼åŸºäºææ–™å†…å®¹ï¼Œä¸ç¼–é€ ã€‚
2. è¯­è¨€æ­£å¼ã€ä¸¥è°¨ã€‚
3. å¦‚æœç”¨æˆ·è¦æ±‚ç”Ÿæˆè¡¨æ ¼ã€åˆ—è¡¨ç­‰ç‰¹å®šæ ¼å¼ï¼Œè¯·åŠ¡å¿…æ»¡è¶³ã€‚
4. è¾“å‡ºå†…å®¹ä½¿ç”¨ Markdown æ ¼å¼æ¸²æŸ“ï¼ˆæ”¯æŒè¡¨æ ¼ã€ç²—ä½“ç­‰ï¼‰ã€‚
5. ç›´æ¥è¾“å‡ºæ­£æ–‡å†…å®¹ï¼Œä¸éœ€è¦JSONæ ¼å¼ã€‚
"""
    else:
        system_content = f"""
ä»Šå¤©æ—¥æœŸï¼š{current_date}
ä½ æ˜¯ä¸€ä¸ªæ”¿åŠ¡ææ–™æ’°å†™è¾…åŠ©AIã€‚

ã€ä»»åŠ¡æŒ‡ä»¤ã€‘
è¯·æ ¹æ®ç›®å½•åç§°â€œ{folder_name}â€å’Œç”¨æˆ·æŒ‡ä»¤è¿›è¡Œé€»è¾‘åˆ›ä½œã€‚
1. è¯­è¨€æ­£å¼ã€ç»“æ„æ¸…æ™°ã€‚
2. å¦‚æœç”¨æˆ·è¦æ±‚ç”Ÿæˆè¡¨æ ¼ã€åˆ—è¡¨ç­‰ç‰¹å®šæ ¼å¼ï¼Œè¯·åŠ¡å¿…æ»¡è¶³ã€‚
3. è¾“å‡ºå†…å®¹ä½¿ç”¨ Markdown æ ¼å¼æ¸²æŸ“ï¼ˆæ”¯æŒè¡¨æ ¼ã€ç²—ä½“ç­‰ï¼‰ã€‚
4. ç›´æ¥è¾“å‡ºæ­£æ–‡å†…å®¹ï¼Œä¸éœ€è¦JSONæ ¼å¼ã€‚
"""

    # 5. æ‰§è¡Œæµå¼ç”Ÿæˆ
    try:
        llm = init_llm_instance(llm_config)
        
        # ç»„è£…æ¶ˆæ¯é“¾ï¼šSystem -> History -> Current Human
        messages = [SystemMessage(content=system_content)]
        messages.extend(current_history)
        messages.append(HumanMessage(content=instruction))
        
        full_response_content = ""

        # æµå¼è¿”å›
        for chunk in llm.stream(messages):
            text_chunk = chunk.content if hasattr(chunk, 'content') else str(chunk)
            if text_chunk:
                full_response_content += text_chunk
                yield f"data: {json.dumps({'content': text_chunk}, ensure_ascii=False)}\n\n"
        
        # ç»“æŸæ ‡è®°
        yield "data: [DONE]\n\n"

        # 6. æ›´æ–°å†å²è®°å½• (å­˜å…¥ Redis/Memory)
        current_history.append(HumanMessage(content=instruction))
        current_history.append(AIMessage(content=full_response_content))
        session_manager.update_session(task_id, current_history)
        logger.info(f"Task {task_id} å†å²è®°å½•å·²æ›´æ–°")

    except Exception as e:
        logger.error(f"Stream error: {e}")
        yield f"data: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"

# å ä½å‡½æ•°ï¼Œå¦‚æœè¿˜éœ€è¦åŒæ­¥æ¥å£å¯ä¿ç•™
def Chat_generator(*args, **kwargs):
    pass


if __name__ == "__main__":
    # --- 1. æµ‹è¯•é…ç½® ---
    TEST_TASK_ID = "local_debug_session_001" 
    INPUT_MODEL_ID = 6   
    INPUT_FOLDER_NAME = "é¡¹ç›®æ¦‚è¿°"
    INPUT_MATERIALS = [
        "æå¼ºä¸»æŒå¬å¼€å›½åŠ¡é™¢å¸¸åŠ¡ä¼šè®® ç ”ç©¶è¿›ä¸€æ­¥åšå¥½èŠ‚èƒ½é™ç¢³å·¥ä½œç­‰  å¹¿ä¸œçœäººæ°‘æ”¿åºœé—¨æˆ·ç½‘ç«™_20251231144447.pdf",
    ]
    
    print(f"\nğŸš€ å¯åŠ¨æœ¬åœ°æµ‹è¯• (Task ID: {TEST_TASK_ID})")
    print(f"ğŸ“‚ åŠ è½½ææ–™æ•°: {len(INPUT_MATERIALS)}")

    # å®šä¹‰ä¸€ä¸ªæµ‹è¯•å‡½æ•°ï¼Œå‡å°‘é‡å¤ä»£ç 
    def run_chat_round(round_num, instruction):
        print(f"\n\n========= ç¬¬ {round_num} è½®å¯¹è¯: {instruction[:15]}... =========")
        
        start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
        first_token_time = None   # ç”¨äºè®°å½•é¦–å­—è¿”å›æ—¶é—´
        
        generator = Chat_generator_stream(
            INPUT_FOLDER_NAME, 
            INPUT_MATERIALS, 
            instruction, 
            INPUT_MODEL_ID, 
            TEST_TASK_ID 
        )
        
        full_content = ""
        for event in generator:
            if "[DONE]" in event:
                break
            
            try:
                # è®°å½•é¦–å­—åˆ°è¾¾æ—¶é—´ï¼ˆæ€è€ƒæ—¶é—´ï¼‰
                if first_token_time is None:
                    first_token_time = time.time()
                    thinking_duration = first_token_time - start_time
                    print(f"ğŸ’¡ æ€è€ƒè€—æ—¶: {thinking_duration:.2f}s (é¦–å­—å·²è¿”å›)\n" + "-"*30)

                json_str = event.replace("data: ", "").strip()
                data = json.loads(json_str)
                
                if "content" in data:
                    chunk = data["content"]
                    print(chunk, end="", flush=True) 
                    full_content += chunk
                
                if "error" in data:
                    print(f"\nâŒ Error: {data['error']}")
            except Exception:
                pass
        
        end_time = time.time() # è®°å½•ç»“æŸæ—¶é—´
        total_duration = end_time - start_time
        print(f"\n\n---------------------------------")
        print(f"â±ï¸ æœ¬è½®ç»Ÿè®¡: æ€»è€—æ—¶ {total_duration:.2f}s")

    # --- 2. ç¬¬ä¸€è½®å¯¹è¯ ---
    INPUT_INSTRUCTION_1 = """
    è¯·ç”Ÿæˆä¸€æ®µçº¦500å­—çš„ææ–™ç»¼è¿°ï¼Œä¸»é¢˜ä¸ºèŠ‚èƒ½é™ç¢³å·¥ä½œæ¨è¿›ã€‚
    å†…å®¹å¿…é¡»åŒ…å«ï¼šèƒŒæ™¯ã€é‡ç‚¹ä¸¾æªã€‚
    è¦æ±‚ï¼šè¯­æ°”æ­£å¼ã€‚
    """
    run_chat_round(1, INPUT_INSTRUCTION_1)

    # --- 3. ç¬¬äºŒè½®å¯¹è¯ (æµ‹è¯•è®°å¿†åŠŸèƒ½) ---
    INPUT_INSTRUCTION_2 = "è¯·æ ¹æ®åˆšæ‰ç”Ÿæˆçš„å†…å®¹ï¼Œæç‚¼å‡º3ä¸ªæ ¸å¿ƒå…³é”®è¯ï¼Œå¹¶è§£é‡Šä¸ºä»€ä¹ˆé€‰å®ƒä»¬ã€‚"
    run_chat_round(2, INPUT_INSTRUCTION_2)
    
    # --- 4. éªŒè¯å†…å­˜çŠ¶æ€ ---
    print("\nâœ… æµ‹è¯•ç»“æŸ")
    history = session_manager.get_session(TEST_TASK_ID)
    if history:
        history_len = len(history)
        print(f"ğŸ“Š å½“å‰ä¼šè¯çŠ¶æ€: Task [{TEST_TASK_ID}] åŒ…å« {history_len} æ¡æ¶ˆæ¯è®°å½•ã€‚")