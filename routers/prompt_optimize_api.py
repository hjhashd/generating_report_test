import json
import logging
from fastapi import APIRouter, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from routers.dependencies import require_user
from utils.lyf.prompt_optimize import prompt_optimize_service

logger = logging.getLogger(__name__)
router = APIRouter()

STREAM_HEADERS = {
    "Cache-Control": "no-cache",
    "Connection": "keep-alive",
    "Content-Type": "text/event-stream",
    "X-Accel-Buffering": "no"
}

class OptimizeRequest(BaseModel):
    raw_prompt: str
    target_scene: str  # ç›®æ ‡åœºæ™¯ï¼Œå¦‚â€œå…¬æ–‡å†™ä½œâ€ã€â€œä»£ç ç”Ÿæˆâ€

@router.post("/prompt_optimize/stream")
async def optimize_stream_endpoint(request: OptimizeRequest, current_user: dict = Depends(require_user)):
    """
    ã€æç¤ºè¯ä¼˜åŒ–ã€‘æµå¼æ¥å£ï¼šå°†å£è¯­åŒ–æç¤ºè¯è½¬ä¸ºç»“æ„åŒ–æŒ‡ä»¤
    """
    logger.info(f"ğŸ› ï¸ [Optimize] User: {current_user.id} æ­£åœ¨ä¼˜åŒ–æç¤ºè¯")

    async def event_generator():
        # è°ƒç”¨ä¼˜åŒ–æœåŠ¡çš„æµå¼æ–¹æ³•
        for chunk in prompt_optimize_service.optimize_stream(request.raw_prompt, request.target_scene):
            yield f"data: {json.dumps({'content': chunk}, ensure_ascii=False)}\n\n"
        yield "data: [DONE]\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream", headers=STREAM_HEADERS)
