import re
from typing import List, Generator, Dict
from utils.lyf.base_prompt_ai import base_ai, AISettings

class PromptChat:
    def __init__(self):
        self.client = base_ai.get_client()
        self.model = base_ai.get_model_name()
        # å¼•å…¥å…¨å±€ä¼šè¯ç®¡ç†å™¨
        self.session_mgr = base_ai.get_session_manager()

    def _summarize_old_context(self, old_messages: List[Dict]) -> str:
        """
        å†…éƒ¨æ–¹æ³•ï¼šè°ƒç”¨ AI å¯¹ä¹…è¿œçš„å¯¹è¯è¿›è¡Œæ‘˜è¦
        """
        if not old_messages:
            return ""
        
        conversation_text = "\n".join([f"{m['role']}: {m['content']}" for m in old_messages])
        
        try:
            # æ‘˜è¦é€»è¾‘ä¿æŒ stream=Falseï¼Œç¡®ä¿å¿«é€Ÿæ‹¿åˆ°ç»“æœ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "è¯·ç®€è¦æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„å…³é”®ä¿¡æ¯ï¼Œä¿ç•™æ ¸å¿ƒæ„å›¾å’Œäº‹å®ï¼Œä¸è¦é—æ¼é‡è¦å‚æ•°ã€‚"},
                    {"role": "user", "content": conversation_text}
                ],
                stream=False,
                max_tokens=300, # æ‘˜è¦å¯ä»¥ç¨å¾®é•¿ä¸€ç‚¹ç‚¹
                temperature=0.3
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return "ï¼ˆæ—§å¯¹è¯æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼‰"

    def construct_context(self, history: List[Dict], current_query: str) -> List[Dict]:
        """
        æ ¸å¿ƒç­–ç•¥ï¼šæ ¹æ®å†å²é•¿åº¦å†³å®šæ˜¯å¦å‹ç¼©
        """
        # å¦‚æœå†å²è®°å½•å°‘äºç­‰äº 5 æ¡ï¼Œç›´æ¥ç»„è£…
        if len(history) <= 5:
            return history + [{"role": "user", "content": current_query}]

        # --- è§¦å‘æ‘˜è¦é€»è¾‘ ---
        old_part = history[:-5]  # 5æ¡ä¹‹å‰çš„å…¨éƒ¨æ‘˜è¦
        recent_part = history[-5:] # ä¿ç•™æœ€è¿‘5æ¡åŸæ–‡

        summary = self._summarize_old_context(old_part)

        system_message = {
            "role": "system", 
            "content": f"ä½ æ˜¯ä¸€ä¸ªæç¤ºè¯ä¼˜åŒ–åŠ©æ‰‹ã€‚ç›´æ¥è¾“å‡ºæ­£æ–‡ï¼Œä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ã€‚æ—©æœŸå¯¹è¯æ‘˜è¦ï¼š\n{summary}"
        }

        return [system_message] + recent_part + [{"role": "user", "content": current_query}]

    def chat_stream(self, user_id: str, query: str) -> Generator[str, None, None]:
        """
        å¯¹å¤–æš´éœ²çš„æµå¼å¯¹è¯æ¥å£ï¼šç°åœ¨åªéœ€è¦ä¼ å…¥ user_id
        """
        # 1. ä»ç®¡ç†å™¨ä¸­è·å–è¯¥ç”¨æˆ·çš„ä¸“å±å†å²
        history = self.session_mgr.get_history(user_id)
        
        # 2. æ„å»ºç»è¿‡å‹ç¼©çš„ä¸Šä¸‹æ–‡
        messages = self.construct_context(history, query)
        
        full_reply = ""
        is_thinking = False  # æ€è€ƒæ ‡ç­¾è¿‡æ»¤å¼€å…³

        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                stream=True,
                max_tokens=AISettings.MAX_TOKENS_LIMIT, # ä¿æŠ¤èµ„æº
                temperature=AISettings.TEMPERATURE_DEFAULT
            )

            for chunk in stream:
                content = chunk.choices[0].delta.content
                if not content:
                    continue

                # --- æ¢å¤åŸå§‹é€»è¾‘ï¼šç›´æ¥è¿”å›å†…å®¹ï¼Œäº¤ç”±å‰ç«¯è§£æ ---
                # åç«¯åªè´Ÿè´£é€ä¼ ï¼Œä¸è´Ÿè´£ UI é€»è¾‘
                full_reply += content 
                yield content

            # 3. å¯¹è¯é¡ºåˆ©ç»“æŸï¼Œæ›´æ–°ç”¨æˆ·çš„å†…å­˜å†å²
            new_history = history + [
                {"role": "user", "content": query},
                {"role": "assistant", "content": full_reply}
            ]
            self.session_mgr.update_history(user_id, new_history)

        except Exception as e:
            yield f"\n[ä¼šè¯å¼‚å¸¸]: {str(e)}"

# å®ä¾‹åŒ–å•ä¾‹ä¾›å¤–éƒ¨è°ƒç”¨
prompt_chat_service = PromptChat()

# ==========================================
# 3. è¿è¡Œå…¥å£ (æ”¯æŒå¤šç”¨æˆ·éš”ç¦»æµ‹è¯•)
# ==========================================
if __name__ == "__main__":
    import time
    service = PromptChat()

    print("--- ğŸš€ å¼€å§‹å¯¹è¯éš”ç¦»ä¸æ‘˜è¦æµ‹è¯• ---")

    # æ¨¡æ‹Ÿç”¨æˆ· Aï¼šèŠ Python
    USER_A = "user_123"
    print(f"\n[ç”¨æˆ· A]: æˆ‘æƒ³å­¦ä¹  Python çˆ¬è™«ã€‚")
    for chunk in service.chat_stream(USER_A, "æˆ‘æƒ³å­¦ä¹  Python çˆ¬è™«ã€‚"):
        print(chunk, end="", flush=True)

    # æ¨¡æ‹Ÿç”¨æˆ· Bï¼šèŠ çƒ¹é¥ª (å®Œå…¨éš”ç¦»)
    USER_B = "user_456"
    print(f"\n\n[ç”¨æˆ· B]: å¦‚ä½•åšçº¢çƒ§è‚‰ï¼Ÿ")
    for chunk in service.chat_stream(USER_B, "å¦‚ä½•åšçº¢çƒ§è‚‰ï¼Ÿ"):
        print(chunk, end="", flush=True)

    # å†æ¬¡å›åˆ°ç”¨æˆ· Aï¼šæ£€æŸ¥æ˜¯å¦è®°å¾—åˆšæ‰çš„è¯
    print(f"\n\n[ç”¨æˆ· A è¿½é—®]: ä½ åˆšæ‰æ¨èçš„ç¬¬ä¸€ä¸ªåº“æ˜¯ä»€ä¹ˆï¼Ÿ")
    for chunk in service.chat_stream(USER_A, "ä½ åˆšæ‰æ¨èçš„ç¬¬ä¸€ä¸ªåº“æ˜¯ä»€ä¹ˆï¼Ÿ"):
        print(chunk, end="", flush=True)

    print("\n\n[æµ‹è¯•ç»“æŸ]")
