import logging
from fastapi import APIRouter, Depends, Query
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional
from routers.dependencies import require_user

# å¼•å…¥æ ¸å¿ƒå‡½æ•°
from utils.zzp.ai_generate_langchain import Chat_generator_stream
# ç¡®ä¿è¿™é‡Œå¼•å…¥äº†æˆ‘ä»¬æ–°å†™çš„ get_prompt_list_by_folder
from utils.zzp.ai_adjustment import optimize_text_stream, get_prompt_list_by_folder
from utils.zzp.ai_summary import ai_summary_stream

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

router = APIRouter()

# ==========================================
# é€šç”¨å“åº”å¤´
# ==========================================
STREAM_HEADERS = {
    "Cache-Control": "no-cache",
    "Connection": "keep-alive",
    "Content-Type": "text/event-stream",
    "X-Accel-Buffering": "no"
}

# ==========================================
# æ•°æ®æ¨¡å‹ (Request Models)
# ==========================================

class GenerateSummaryRequest(BaseModel):
    task_id: str
    status: int
    agentUserId: int
    id: int                       # æ¨¡å‹ID
    folder_name: str              
    material_name_list: List[str] 
    instruction: str              

class OptimizeTextRequest(BaseModel):
    task_id: str                
    status: int
    agentUserId: int
    id: int                     # æ¨¡å‹ID
    text: str                   
    prompt_ids: List[int]       # å‰ç«¯é€‰ä¸­çš„ ID åˆ—è¡¨

class SummaryRequest(BaseModel):
    task_id: str                
    status: int
    agentUserId: int
    id: int                     
    text: str
    instruction: Optional[str] = None

# ==========================================
# 1. æç¤ºè¯ç®¡ç†æ¥å£ (æ–°å¢)
# ==========================================

@router.get("/Prompts_List/")
async def get_prompts_endpoint(
    folder_id: int = Query(..., description="æ–‡ä»¶å¤¹ID"),
    current_user: dict = Depends(require_user)
):
    """
    ã€è·å–æç¤ºè¯åˆ—è¡¨ã€‘
    åŠŸèƒ½ï¼šå‰ç«¯æ¸²æŸ“ä¸‹æ‹‰åˆ—è¡¨å‰ï¼Œå…ˆè°ƒç”¨æ­¤æ¥å£è·å–å½“å‰æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æç¤ºè¯ (ID å’Œ æ ‡é¢˜)
    """
    # [ä¿®æ”¹] å¼ºåˆ¶å†™æ­»ä¸ºç”¨æˆ· 7 å’Œ æ–‡ä»¶å¤¹ 402ï¼Œå› ä¸ºåªæœ‰è¯¥é…ç½®ä¸‹æœ‰å…¬å¼€çš„æç¤ºè¯æ•°æ®
    user_id = 7 
    target_folder_id = 402
    logger.info(f"ğŸ” [åˆ—è¡¨] ç”¨æˆ· {current_user.id} è¯·æ±‚æ–‡ä»¶å¤¹ {folder_id} çš„æç¤ºè¯åˆ—è¡¨ (å¼ºåˆ¶ä½¿ç”¨ç”¨æˆ·7å’Œæ–‡ä»¶å¤¹402çš„æ•°æ®)")
    
    # è°ƒç”¨ utils é‡Œçš„æŸ¥è¯¢å‡½æ•°
    prompts = get_prompt_list_by_folder(target_folder_id, user_id)
    
    return {
        "code": 200,
        "data": prompts,  # è¿”å›ç¤ºä¾‹: [{"id": 591, "title": "å•†åŠ¡æ¶¦è‰²"}, {"id": 592, "title": "å»å£è¯­åŒ–"}]
        "msg": "success"
    }

# ==========================================
# 2. æ ¸å¿ƒæµå¼ä¸šåŠ¡æ¥å£
# ==========================================

@router.post("/Optimize_Text_Stream/")
async def Optimize_Text_Stream_endpoint(request: OptimizeTextRequest, current_user: dict = Depends(require_user)):
    """
    ã€æ¶¦è‰²ä¼˜åŒ–ã€‘æµå¼æ¥å£
    """
    # [ä¿®æ”¹] å¼ºåˆ¶å†™æ­»ä¸ºç”¨æˆ· 7ï¼Œä»¥ä½¿ç”¨è¯¥ç”¨æˆ·çš„å…¬å¼€æç¤ºè¯æ¨¡æ¿è¿›è¡Œæ¶¦è‰²
    user_id = 7
    logger.info(f'âœ¨ [æ¶¦è‰²] æ¥æ”¶ä»»åŠ¡: {request.task_id} | çœŸå®ç”¨æˆ·: {current_user.username} (å¼ºåˆ¶ä½¿ç”¨ç”¨æˆ·7çš„æƒé™)')
    logger.info(f'    åŸæ–‡é•¿åº¦: {len(request.text)}, Prompt IDs: {request.prompt_ids}')

    return StreamingResponse(
        optimize_text_stream(
            text=request.text,
            prompt_ids=request.prompt_ids,
            model_id=request.id,
            task_id=request.task_id,
            user_id=user_id
        ),
        media_type="text/event-stream",
        headers=STREAM_HEADERS
    )

@router.post("/Generate_Summary_Stream/")
async def Generate_Summary_Stream_endpoint(request: GenerateSummaryRequest, current_user: dict = Depends(require_user)):
    """
    ã€å†™ä½œç”Ÿæˆã€‘æµå¼æ¥å£
    """
    user_id = current_user.id
    return StreamingResponse(
        Chat_generator_stream(
            folder_name=request.folder_name,
            material_name_list=request.material_name_list,
            instruction=request.instruction,
            model_id=request.id,    
            task_id=request.task_id,
            user_id=user_id
        ),
        media_type="text/event-stream",
        headers=STREAM_HEADERS
    )

@router.post("/ai_summary/stream")
async def api_summary(req: SummaryRequest, current_user: dict = Depends(require_user)):
    """
    ã€æ–‡æœ¬æ€»ç»“ã€‘æµå¼æ¥å£
    """
    return StreamingResponse(
        ai_summary_stream(req.text, req.id, req.instruction, current_user.id),
        media_type="text/event-stream",
        headers=STREAM_HEADERS
    )

# ==========================================
# 3. ç³»ç»Ÿæ£€æŸ¥
# ==========================================
@router.get("/health")
def health_check():
    return {"status": "healthy"}